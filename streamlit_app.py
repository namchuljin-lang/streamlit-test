# âœ… ì •ë¦¬ëœ import (ì¤‘ë³µ ì—†ì´ ì •í™•í•œ ë²„ì „)
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.document_loaders import PyPDFLoader
from langchain.tools.retriever import create_retriever_tool
from langchain.agents import create_tool_calling_agent, AgentExecutor, Tool
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_community.utilities import SerpAPIWrapper
from langchain.prompts import ChatPromptTemplate
import streamlit as st
import tempfile
import os

def search_web():
    search = SerpAPIWrapper()
    def run_with_source(query: str) -> str:
        results = search.results(query)
        organic = results.get("organic_results", [])
        formatted = []
        for r in organic[:5]:
            title = r.get("title")
            link = r.get("link")
            source = r.get("source")
            snippet = r.get("snippet")
            if link:
                formatted.append(f"- [{title}]({link}) ({source})\n  {snippet}")
            else:
                formatted.append(f"- {title} (ì¶œì²˜: {source})\n  {snippet}")
        return "\n".join(formatted) if formatted else "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    return Tool(
        name="web_search",
        func=run_with_source,
        description="ì‹¤ì‹œê°„ ë‰´ìŠ¤ ë° ì›¹ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ê²°ê³¼ëŠ” ì œëª©+ì¶œì²˜+ë§í¬+ê°„ë‹¨ìš”ì•½(snippet) í˜•íƒœë¡œ ë°˜í™˜ë©ë‹ˆë‹¤."
    )


def load_pdf_files(uploaded_files):
    all_documents = []
    for uploaded_file in uploaded_files:
        # ì„ì‹œ íŒŒì¼ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.read())
            tmp_file_path = tmp_file.name

        # PDF ë¡œë“œ
        loader = PyPDFLoader(tmp_file_path)
        documents = loader.load()
        all_documents.extend(documents)

    # âœ… í…ìŠ¤íŠ¸ë¥¼ ë” ì˜ê²Œ ë¶„í•  (ê¸°ì¡´ë³´ë‹¤ ì‘ê²Œ)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=150)
    split_docs = text_splitter.split_documents(all_documents)

    st.info(f"ğŸ” ì´ {len(split_docs)}ê°œì˜ ë¬¸ì„œ ì²­í¬ë¡œ ë¶„í• ë˜ì—ˆìŠµë‹ˆë‹¤.")

    embeddings = OpenAIEmbeddings()
    vectors = []
    metadatas = []

    # âœ… ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì•ˆì „í•˜ê²Œ ì„ë² ë”© (í•œ ë²ˆì— ë„ˆë¬´ ë§ì´ ì•ˆ ë³´ëƒ„)
    batch_size = 80
    for i in tqdm(range(0, len(split_docs), batch_size), desc="Embedding in batches"):
        batch = split_docs[i:i + batch_size]
        texts = [doc.page_content for doc in batch]
        meta = [doc.metadata for doc in batch]

        try:
            batch_embeddings = embeddings.embed_documents(texts)
            vectors.extend(batch_embeddings)
            metadatas.extend(meta)
        except Exception as e:
            st.error(f"âš ï¸ ì„ë² ë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë°°ì¹˜ {i // batch_size + 1}): {e}")
            continue

    # âœ… FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
    vector = FAISS.from_embeddings(
        embeddings=vectors,
        metadatas=metadatas,
        embedding=embeddings
    )

    retriever = vector.as_retriever()

    retriever_tool = create_retriever_tool(
        retriever,
        name="pdf_search",
        description="Use this tool to search information from the uploaded PDF documents."
    )

    return retriever_tool


# âœ… Agent ëŒ€í™” ì‹¤í–‰
def chat_with_agent(user_input, agent_executor):
    result = agent_executor({"input": user_input})
    return result['output']

# âœ… ì„¸ì…˜ë³„ íˆìŠ¤í† ë¦¬ ê´€ë¦¬
def get_session_history(session_ids):
    if session_ids not in st.session_state.session_history:
        st.session_state.session_history[session_ids] = ChatMessageHistory()
    return st.session_state.session_history[session_ids]

# âœ… ì´ì „ ë©”ì‹œì§€ ì¶œë ¥
def print_messages():
    for msg in st.session_state["messages"]:
        st.chat_message(msg['role']).write(msg['content'])

# âœ… ë©”ì¸ ì‹¤í–‰
def main():
    st.set_page_config(page_title="AI ë¹„ì„œ", layout="wide", page_icon="ğŸ¤–")

    with st.container():
        st.image('./chatbot_logo.png', use_container_width=True)
        st.markdown('---')
        st.title("ì•ˆë…•í•˜ì„¸ìš”! RAGë¥¼ í™œìš©í•œ 'AI ë¹„ì„œ í†¡í†¡ì´' ì…ë‹ˆë‹¤")

    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    if "session_history" not in st.session_state:
        st.session_state["session_history"] = {}

    with st.sidebar:
        st.session_state["OPENAI_API"] = st.text_input("OPENAI API í‚¤", placeholder="Enter Your API Key", type="password")
        st.session_state["SERPAPI_API"] = st.text_input("SERPAPI_API í‚¤", placeholder="Enter Your API Key", type="password")
        st.markdown('---')
        pdf_docs = st.file_uploader("Upload your PDF Files", accept_multiple_files=True, key="pdf_uploader")

    # âœ… í‚¤ ì…ë ¥ í™•ì¸
    if st.session_state["OPENAI_API"] and st.session_state["SERPAPI_API"]:
        os.environ['OPENAI_API_KEY'] = st.session_state["OPENAI_API"]
        os.environ['SERPAPI_API_KEY'] = st.session_state["SERPAPI_API"]

        # ë„êµ¬ ì •ì˜
        tools = []
        if pdf_docs:
            pdf_search = load_pdf_files(pdf_docs)
            tools.append(pdf_search)
        tools.append(search_web())

        # LLM ì„¤ì •
        llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0)

        prompt = ChatPromptTemplate.from_messages(
            [
                ("system",
                "Be sure to answer in Korean. You are a helpful assistant. "
                "Make sure to use the `pdf_search` tool for searching information from the pdf document. "
                "If you can't find the information from the PDF document, use the `web_search` tool for searching information from the web. "
                "If the userâ€™s question contains words like 'ìµœì‹ ', 'í˜„ì¬', or 'ì˜¤ëŠ˜', you must ALWAYS use the `web_search` tool to ensure real-time information is retrieved. "
                "Please always include emojis in your responses with a friendly tone. "
                "Your name is `AI ë¹„ì„œ í†¡í†¡ì´`. Please introduce yourself at the beginning of the conversation."),
                ("placeholder", "{chat_history}"),
                ("human", "{input} \n\n Be sure to include emoji in your responses."),
                ("placeholder", "{agent_scratchpad}"),
            ]
        )


        agent = create_tool_calling_agent(llm, tools, prompt)
        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

        # ì…ë ¥ì°½
        user_input = st.chat_input('ì§ˆë¬¸ì´ ë¬´ì—‡ì¸ê°€ìš”?')

        if user_input:
            session_id = "default_session"
            session_history = get_session_history(session_id)

            if session_history.messages:
                prev_msgs = [{"role": msg['role'], "content": msg['content']} for msg in session_history.messages]
                response = chat_with_agent(user_input + "\n\nPrevious Messages: " + str(prev_msgs), agent_executor)
            else:
                response = chat_with_agent(user_input, agent_executor)

            st.session_state["messages"].append({"role": "user", "content": user_input})
            st.session_state["messages"].append({"role": "assistant", "content": response})

            session_history.add_message({"role": "user", "content": user_input})
            session_history.add_message({"role": "assistant", "content": response})

        print_messages()

    else:
        st.warning("OpenAI API í‚¤ì™€ SerpAPI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()
